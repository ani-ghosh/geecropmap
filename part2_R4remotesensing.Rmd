---
title: "Chapter II: Introduction to Remote Sensing with R"
author:
- Ani Ghosh (anighosh@ucdavis.edu)
- Robert Hijmans (rhijmans@ucdavis.edu)
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: default
  html_document: default
urlcolor: blue  
---
# Part I

```{r setup, echo=TRUE, include=FALSE}
library(knitr)
opts_chunk$set(
  fig.width  = 6,
	fig.height = 6,
	fig.cap = '',
	collapse  = TRUE,
  tidy.opts=list(width.cutoff=60),
  tidy=TRUE
)

knitr::opts_knit$set(root.dir = '/data/Google-Drive/lecture-notes/remotesensing-rspatial/rsdata')
knitr::opts_chunk$set(cache = TRUE)
```

## Introduction

This page provides a short introduction to satellite data analysis with R. Before reading this you should first learn the [basics of the raster package](http://rspatial.org/spatial/). 

Getting satellite images for a specific project remains one of the most challenging steps in the workflow. You have to find the data most suitable for you particular objective. A few important properties to consider while searching the remotely sensed (satellite) data include:

1. Spatial resolution (pixel size) [*reference*](http://www.nrcan.gc.ca/node/9407)
2. Temporal resolution (return time; availability of histrotical images, and for a particular moment in time) [*reference*](http://www.seos-project.eu/modules/remotesensing/remotesensing-c03-p05.html)
3. Number of spectral bands (wavelengths) [*reference*](http://www.seos-project.eu/modules/remotesensing/remotesensing-c03-p03.html)
4. Quality (e.g. cloud-cover or artifacts in data (read about problems in [Landsat ETM+](http://landsat.usgs.gov/products_slcoffbackground.php))


There are numerous sources of remotely sensed data from satellites. Generally, the very high spatial resolution data is available as (costly) commercial products. Lower spatial resolution data is freely available from NASA, ESA and other missions. In this tutorial we'll use freely available [Landsat 8](https://landsat.gsfc.nasa.gov/landsat-8/), [Landsat 7](https://landsat.gsfc.nasa.gov/landsat-7/), [Landsat 5](https://landsat.gsfc.nasa.gov/landsat-5/), [Sentinel](https://earth.esa.int/web/sentinel/user-guides/sentinel-2-msi) and [MODIS](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table) data. Landsat program is the longest running Earth-observation satellite program with [series of satellites](https://landsat.gsfc.nasa.gov/a-landsat-timeline/) launched over the last four decades.

You can access these data from several sources, including: 

i. <http://earthexplorer.usgs.gov/>
ii. <https://lpdaacsvc.cr.usgs.gov/appeears/>
iii. <https://search.earthdata.nasa.gov/search>
iv. <https://lpdaac.usgs.gov/data_access/data_pool>
v. <https://scihub.copernicus.eu/>
vi. <https://aws.amazon.com/public-data-sets/landsat/>

This [web site](http://gisgeography.com/free-satellite-imagery-data-list/) lists 15 sources of freely available remote sensing data.

It is possible to download some satellite data using R-packages. You can use [luna](https://github.com/rspatial/luna), [MODIS](https://cran.r-project.org/web/packages/MODIS/index.html) or [MODISTools](https://cran.r-project.org/web/packages/MODISTools/index.html) package to search, download and pre-process different [MODIS products](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table).

### Tutorial data  

You can download all the data required for completing this tutorial from this **[link](https://drive.google.com/drive/folders/1Rl1v3a8XXY6u3z6rLi4NcldbP1IVnIpH)**. Save the data to your working directory in your local computer. Unzip the 'LC08_044034_20170614.zip' folder for part I.  


## Landsat data used in this tutorial 

For the first exercise, we will primarily use a spatial subset of Landsat 8 scene collected on June 14, 2017.The subset covers the area between Concord and Stockton, CA and has multiple land use land cover classes.    
All Landsat image scenes have unique product ID and metadata. You can find the information on Landsat sensor, satellite, [location on Earth (WRS path, WRS row)](https://landsat.usgs.gov/what-worldwide-reference-system-wrs) and Acquisition date from the product id. E.g. the product identifier of the image tile you are using is 'LC08_044034_20170614'. Based on [this guide](https://landsat.usgs.gov/landsat-collections#Prod IDs), you can see that the Sensor-Satellite is OLI/TIRS combined Landsat 8, WRS Path 44, WRS Row 34 and collected on June 14, 2017. Landsat scenes are most commonly delivered as zipped file, which contains single image layers representing the different bands captured by the sensors at various wavelengths. 

We will start by exploring and visualizing this data.

## Basic image manipulation and visualization

In this section we describe how to access and explore attributes of remote sensing images with R. All the images used here are in a raster format. You also learn to plot the raster data in R and understand the difference between single- and multi-band rasters.

### Read image and display basic image properties 

All these products consist of sensors that measure reflectance of the sun's radiation in different wavelengths (e.g. in the red, green, or blue wavelengths). Thus one image consists of multiple spectral layers. In remote sensing jargon, such layers are referred to as "bands" (shorthand for "bandwidth"" in the electromagnetic spectrum). From such multi-spectral data you can create a `RasterBrick` or `RasterStack` in R (as long as each layer has the same extent and resolution). 

Another piece of jargon is "pixel". This is the term that is used for grid cell in remote sensing literature. 

```{r}
library(raster)

#load a single Landsat band
# Blue band
b2 <- raster('LC08_044034_20170614_B2.tif')

# Green band
b3 <- raster('LC08_044034_20170614_B3.tif')

# Red band
b4 <- raster('LC08_044034_20170614_B4.tif')

# Near Infrared (NIR) band
b5 <- raster('LC08_044034_20170614_B5.tif')

# Now print the variables
b2
# Also check b3,b4,b5
```

You can see the spatial resolution, extent, number of layers, coordinate reference system and more.


### Image information and statistics

The below shows how you can access various properties from the Raster layer (this is the same for any raster data set).

```{r}
# coordinate reference system (CRS)
crs(b2)

# Number of rows, columns, or cells
ncell(b2)
dim(b2)

# spatial resolution
res(b2)

# Number of bands
nlayers(b2)

# Do the bands have the same extent, number of rows and columns, projection, resolution, and origin 
compareRaster(b2,b3)
```

You can create RasterStack/RasterBrick (multiband image) using the raster layers (single band image).

```{r}
landsatRGB <- stack(b4,b3,b2)
landsatFCC <- stack(b5,b4,b3)

# Check the properties of the RasterStack
landsatRGB
```

Notice the order of the layers. These are suitable for plotting different color composites. You can learn more about color composites in remote sensing [here](https://crisp.nus.edu.sg/~research/tutorial/opt_int.htm) and also in the section below.

You can also create the RasterStack/RasterBrick using layers from disk.

```{r}
# first create a list of raster layers to use
raslist <- paste0("LC08_044034_20170614_B", 1:11, ".tif")
raslist

landsat <- stack(raslist)
landsat
```

This will create a RasterStack with 11 layers. The layers are Ultra Blue, Blue, Green, Red, Near Infrared (NIR), Shortwave Infrared (SWIR) 1, Shortwave Infrared (SWIR) 2, Panchromatic, Cirrus, Thermal Infrared (TIRS) 1, Thermal Infrared (TIRS) 2. There is no need for the last four layers and we will learn how to remove those in following sections. 

### Visualize single and multi-band imagery

You can plot individual layers of a multi-spectral image.

```{r fig.width  = 8, fig.height = 8}
par(mfrow = c(2,2))
plot(b2, main = "Landsat Blue Wavelength", col = gray(0:100 / 100))
plot(b3, main = "Landsat Green Wavelength", col = gray(0:100 / 100))
plot(b4, main = "Landsat Red Wavelength", col = gray(0:100 / 100))
plot(b5, main = "Landsat NIR Wavelength", col = gray(0:100 / 100))
```

Check the legends. They represent the range of each layers and are scaled between 0 and 1. Notice the difference in shading and range of legends between the different bands. This is because different Earth surface features reflect the incident solar radiation differently. Each layer represent how much incident solar radiation is reflected for that particular wavelength. E.g. vegetation reflects more energy in NIR than other wavelengths and thus appears brighter in NIR wavelength. However water absorbs most of the incident energy in NIR regions and appears dark.    

However we did not get much information from these grey-scale plots, but these are often combined to create more interesting plots. To combine three bands, we can use `plotRGB`. To make a "true/natural color" image (that is, something that looks like a normal photograph), we need to  select the bands that we want to render in the red, green and blue regions. For this Landsat image, r = 3 (red), g = 2(green), b = 1(blue) will plot the true color composite (vegetation in green, water blue etc). You can also supply additional arguments to `plotRGB` to improve the visualization (e.g. a linear stretch of the values, using `strecth = "lin"`). 

```{r truecolor}
plotRGB(landsatRGB, r = 1, g = 2, b = 3, axes = TRUE, stretch = "lin", main = "Landsat True Color Composite")
```

This RGB-plot has lot more information than the previous ones, although it has been created using the same bands. Another popular image visualization method in remote sensing is known "false color" image where red, green and blue bands are replaced by other bands. Selecting r = NIR, g = red, b = green will plot a "false color"" composite. This representation is popular as it makes it easy to see the vegetation (in red).

```{r fig.width  = 8, fig.height = 4}
par(mfrow = c(1,2))
plotRGB(landsatRGB, r = 1, g = 2, b = 3, axes = TRUE, stretch = "lin", main = "Landsat True Color Composite")
plotRGB(landsatFCC, r = 1, g = 2, b = 3, axes = TRUE, stretch = "lin", main = "Landsat False Color Composite")
```

*Note*: Always check for package documentation (`help(plotRGB)`) for other arguments that can be added (like scale) to improve or modify the image.

**Exercise** Use the RasterStack `landsat` to create a true and false color composite (*hint* remember the position of the bands in the stack). 

### Subset and rename spectral bands

You can select specific layers (bands) using `subset` function, or via indexing.

```{r}
# select first 3 bands only
landsatsub1 <- subset(landsat, 1:3)
# same
landsatsub2 <- landsat[[1:3]]

# Number of bands in orginal and new data
nlayers(landsat)
nlayers(landsatsub1)
nlayers(landsatsub2)
```

As mentioned before, there is no need for the last four bands in`landsat`. You can remove those using

```{r}
landsat <- subset(landsat, 1:7)
```

Set the names of the bands using the following:

```{r}
names(landsat)
names(landsat) <- c('ultra-blue','blue','green','red','NIR','SWIR1','SWIR2')
names(landsat)
```

### Spatial subset or crop

Spatial subsetting can be used to limit analysis to a geographic subset of the image. Spatial subsets can be created with the `crop` function, using an `extent` object, or another spatial object from which an Extent can be extracted/created,. 

```{r, fig.width = 10}
# Using extent
extent(landsat)
e <- extent(624387, 635752, 4200047, 4210939)

# crop landsat by the extent
landsatcrop <- crop(landsat, e)
```

**Exercise** Interactive selection from the image is also possible. Use `drawExtent` and `drawPoly` to select an area of interest. *Note*: drawing will not work for plots generated within the markdown document. Please run the `plot` and `draw` commands from RStudio console.

**Exercise** Use the RasterStack `landsatcrop` to create a true and false color composite (*hint* remember the position of the bands in the stack).

### Saving results to disk
At this stage we may want to save the raster to disk using the function `writeRaster`. Multiple file types are supported. Most commonly we will use GeoTiff format which saves the CRS, extent and resolution information so the data can be used in a different GIS program as well. While layer order is preserved, layer names are lost in GeoTiff format.

```{r}
writeRaster(landsatcrop,filename = "cropped-landsat.tif", format = "GTiff", overwrite = TRUE)
```

*Note*: Check for package documentation (`help(writeRaster)`) for additional helpful arguments that can be added.


### Relation between bands
A scatterplot matrix can be helpful in exploring relationships between raster layers. This can be done with the pairs() function of the raster package.

```{r   fig.width  = 5, fig.height = 5}
# Plot between ultra-blue and blue
pairs(landsatcrop[[1:2]], main = "Scatterplot between Ultra-blue and Blue")

# Plot between ultra-blue and blue
pairs(landsatcrop[[4:5]], main = "Scatterplot between Red and NIR")
```

The first plot reveals high correlations between the blue wavelength regions. Because of the high correlation, we can just use one of the Blue bands without losing much information. 

This distribution of points in second plot (between NIR and Red) is unique due to its triangular shape. Vegetation reflects very highly in the NIR range than red and creates the upper corner close to NIR (y) axis. Water absorbs energy from all the bands and occupies the location close to origin. The furthest corner is created due to highly reflecting surface features like bright soil, concrete.  

### Extract raster values

Often we require value(s) of raster cell(s) for a geographic location/area. The `extract` function is used to get raster values at the locations of other spatial data. You can use points, lines, polygons or an Extent (rectangle) object. You can also use cell numbers to extract values.If using points, extract returns the values of a `Raster*` object for the cells in which a set of points fall. 

```{r}
# load the polygons with land use land cover information
samp <- readRDS('samples.rds')

# generate 300 point samples from the polygons; 
ptsamp <- spsample(samp, 300, type = 'random')
# add the class information to the point samples from polygons
ptsamp$class <- over(ptsamp, samp)$class

# extract values with points
df <- extract(landsat, ptsamp)

# To see some of the reflectance values
head(df)
```

### Spectral profiles

A plot of the spectrum (all bands) for pixels representing a certain earth surface features (e.g. water) is known as a spectral profile. Such profiles demonstrate the differences in spectral properties of various earth surface features and constitute the basis for image analysis. Spectral values can be extracted from any multispectral data set using `extract` function. In the above example, we extracted values of Landsat data for the samples. These samples include: cropland, water, fallow, built and open. First we compute the mean reflectance values for each class and each band.

```{r}
ms <- aggregate(df, list(ptsamp$class), mean)
  
# instead of the first column, we use rownames 
rownames(ms) <- ms[,1]
ms <- ms[,-1]
ms
```

Now we will plot the mean spectra of these features. 

```{r fig.width  = 6, fig.height = 4}
# Create a vector of color for the land cover classes for use in plotting
mycolor <- c('darkred','yellow','burlywood','cyan','blue')

#transform ms from a data.frame to a matrix
ms <- as.matrix(ms)

# First create an empty plot
plot(0, ylim=c(0,0.6), xlim = c(1,7), type='n', xlab="Bands", ylab = "Reflectance")

# add the different classes
for (i in 1:nrow(ms)){
  lines(ms[i,], type = "l", lwd = 3, lty = 1, col = mycolor[i])
}

# Title
title(main="Spectral Profile from Landsat", font.main = 2)

# Legend
legend("topleft", rownames(ms), 
       cex=0.8, col=mycolor, lty = 1, lwd =3, bty = "n")
```

The spectral profile shows (dis)similarity in the reflectance of different features on the earth's surface (or above it). Crop shows similar spectral signatures as vegetation. Water shows relatively low reflection in all wavelengths. Built, fallow and open show relatively higher reflectance in the longer wavelength regions.

## Basic mathematical operations

The `raster` package supports many mathematical operations. Math operations are generally performed per pixel. First we will learn about basic arithmetic operations on bands. First example is a custom math function that calculates the Normalized Difference Vegetation Index (NDVI). Learn more about [vegetation indices here] (http://www.un-spider.org/links-and-resources/data-sources/daotm/daotm-vegetation) and [NDVI](http://phenology.cr.usgs.gov/ndvi_foundation.php).


### Compute vegetation indices
Let's define a general function for ratio based vegetation index.

```{r ndvi}
# i and k are the index of bands to be used for the indices computation

VI <- function(img, k, i) {
  bk <- img[[k]] 
  bi <- img[[i]]
  vi <- (bk - bi) / (bk + bi)
  return(vi)
}

# For Landsat NIR = 5, red = 4.
ndvi <- VI(landsat,5, 4)
plot(ndvi, col = rev(terrain.colors(10)), main = 'Landsat-NDVI')

```

You can see the variation in greenness from the plot.

**Exercise** Adapt the function to compute indices which will highlight i) water and ii) built-up. Hint: Use the spectral profile plot to find the bands having maximum and minimum reflectance for these two classes. 

### Histogram
We can explore the distribution of values contained within our raster using the hist() function which produces a histogram. Histograms are often useful in identifying outliers and bad data values in our raster data. 

```{r}
# view histogram of data
hist(ndvi,
     main = "Distribution of NDVI values",
     xlab = "NDVI",
     ylab="Frequency",
     col = "wheat",
     xlim = c(-0.5, 1),
     breaks = 30,
     xaxt = 'n')
axis(side=1, at = seq(-0.5,1, 0.05), labels = seq(-0.5,1, 0.05))
```
We will refer to this histogram for the following sub-section on thresholding.

**Exercise** Plot histogram of other vegetation indices you derived.

### Thresholding

We can apply basic rules to get an estimate of spatial extent of different Earth surface features. Note that NDVI values are standardized and ranges between -1 to +1. Higher values indicate more green cover. 

Pixels having NDVI values greater than 0.4 are definitely vegetation. Following operation masks all non-vegetation pixels.

```{r}
veg <- calc(ndvi, function(x){x[x < 0.4] <- NA; return(x)})
plot(veg, main = 'Veg cover')
```

Let's find the surface feature corresponding to the peak between 0.25 and 0.3 in the NDVI histogram.

```{r}
land <- reclassify(ndvi, c(-Inf,0.25,NA,0.25,0.3,1,0.3,Inf,NA))
plot(land, main = 'What is it?')
```

My best guess is these are the open areas. You can plot `land` over original `landsatFCC` raster to find out more.

```{r}
plotRGB(landsatRGB, r = 1, g = 2, b = 3, axes = TRUE, stretch = "lin", main = "Landsat False Color Composite")
plot(land, add = TRUE, legend = FALSE)
```

You can also create classes for different amount of vegetation presence. 

```{r}
vegc <- reclassify(veg, c(-Inf,0.25,1, 0.25,0.3,2, 0.3,0.4,3, 0.4,0.5,4, 0.5,Inf, 5))
plot(vegc,col = rev(terrain.colors(4)), main = 'NDVI based thresholding')
```

**Exercise** Is it possible to find water using thresholding of NDVI or any other indices?


### Principal component analysis

Multi-spectral data are sometimes transformed to helps to reduce the dimensioanlity and noise in the data. The principal components transform is a generic data reduction method that can be used to create a few uncorrelated bands from a larger set of correlated bands.

You can calculate the same number of principal components  as the number of input bands. The first principal component (PC) explains the largest percentage of variance and other PCs explain additional the variance in decreasing order. 

```{r pca}
set.seed(1)
sr <- sampleRandom(landsat, 10000)
plot(sr[,c(4,5)], main = "NIR-Red plot")
```

This is known as vegetation and soil-line plot (Same as the scatter plot in earlier section).  

**Exercise** Can you guess the directions of 'principal components' from this scatter plot?

```{r}
pca <- prcomp(sr, scale = TRUE)
pca
screeplot(pca)

pci <- predict(landsat, pca, index = 1:2)
plot(pci[[1]])
```

The first principal component highlights the boundaries between land use classes or spatial details, which is the most common information among all wavelengths. it is difficult to understand what the second principal component is highlighting. Lets try thresholding again:

```{r fig.width  = 8, fig.height = 4}
pc2 <- reclassify(pci[[2]], c(-Inf,0,1,0,Inf,NA))
par(mfrow = c(1,2))
plotRGB(landsatFCC, r = 1, g = 2, b = 3, axes = TRUE, stretch = "lin", main = "Landsat False Color Composite")
plotRGB(landsatFCC, r = 1, g = 2, b = 3, axes = TRUE, stretch = "lin", main = "Landsat False Color Composite")
plot(pc2, legend = FALSE, add = TRUE)
```

**Exercise** Can you guess the surface features dominating second principal component? (*hint*: Inspect the unmasked areas; there could be multiple features).


To learn more about the information contained in the vegetation and soil line plots read this paper by [Gitelson et al] (http://www.tandfonline.com/doi/abs/10.1080/01431160110107806#.V6hp_LgrKhd).  
An extension of PCA in remote sensing is known as [Tasseled-cap Transformation](http://wiki.landscapetoolbox.org/doku.php/remote_sensing_methods:tasseled-cap_transformation).


---
title: "Introduction to Remote Sensing Image Analysis using R"
output:
  pdf_document: default
  html_document: default
urlcolor: blue
---
# Part II

## Image classification

We will explore two groups of classification methods: unsupervised and supervised. Various unsupervised and supervised classification algorithms exist, and the choice of algorithm can affect the results. We will explore one unsupervised (k-means) and two supervised (decision tree, random forest) algorithms.

For this example, we will follow the [National Land Cover Database 2011 (NLCD 2011)](https://www.mrlc.gov/nlcd2011.php) classification scheme for a subset of the Central Valley regions. You will use cloud-free composite image from [Landsat 5](https://landsat.gsfc.nasa.gov/landsat-5/) with 6 bands.

```{r}
landsat5 <- stack('ABT182-centralvalley-2011LT5.tif')
names(landsat5) <- c('blue','green','red','NIR','SWIR1','SWIR2')
```

**Exercise 1** Make a 3-band False Color Composite plot of `landsat5`.

### Unsupervised classification

In unsupervised classification, we don't supply any training data. This particularly is useful when we don't have prior knowledge of the study area. The algorithm groups pixels with similar spectral characteristics into unique clusters/classes/groups following some statistically determined conditions (e.g. minimizing mean square root error within each cluster). You have to re-label and combine these spectral clusters into information classes (for e.g. land-use land-cover). Unsupervised algorithms are often referred as clustering.

To get satisfactory results from unsupervised classification, a good practice is to start with large number of centers (more clusters) and merge/group/recode similar clusters by inspecting the original imagery.

Learn more about K-means and other unsupervised-supervised algorithms [here](http://nptel.ac.in/courses/105108077/module5/lecture19.pdf).

We will perform unsupervised classification on a spatial subset of the `ndvi` layer.

**Exercise 2** Please generate `ndvi` layer for `landsat5` (*hint* last week's lab instructions)

```{r echo = FALSE}
ndvi <- (landsat5[[4]]-landsat5[[3]])/(landsat5[[4]]+landsat5[[3]])
```

Now we will perform unsupervised `kmeans` clustering on the `ndvi` layer you generated in exercise 2. First we will `crop` the `ndvi` layer for smaller extent for faster processing (you can select any `extent` using the `drawExtent()` function). Please **DO NOT** use `landsat5` RasterStack for the clustering. 

#### kmeans classification
```{r kmeans, fig.width = 8, fig.height = 4}
# Extent to crop ndvi layer
e <- extent(-121.807, -121.725, 38.004, 38.072)

# crop landsat by the extent
ndvi <- crop(ndvi, e)
ndvi

# convert the raster to vecor/matrix
nr <- getValues(ndvi)
str(nr)
```

Please note that `getValues` converted the `ndvi` RasterLayer to array. Now we will perform the `kmeans` clustering on the array object and inspect the output. 

```{r kmeansobject}

# It's important to set the seed generator because `kmeans` initiates the centers in radom locations
set.seed(99)

# We want to create 10 clusters, allow 500 iterations, start with 5 random sets using "Lloyd" method
kmncluster <- kmeans(na.omit(nr), centers = 10, iter.max = 500, nstart = 5, algorithm="Lloyd")

# kmeans returns an object of class "kmeans"
str(kmncluster)
```
`kmeans` returns an object with 9 elements. The length of the `cluster` element within `kmncluster` is `r length(kmncluster$cluster)` which same as length of `nr` created from the `ndvi`. The cell values of `kmncluster$cluster` range between 1 to 10 corresponding to the input number of cluster we provided in the `kmeans` function. `kmncluster$cluster` indicates the cluster label for corresponding pixel. We need to convert the `kmncluster$cluster` array back to RasterLayer of the same dimension as the `ndvi`.

```{r kmeansraster}
# First create a copy of the ndvi layer 
knr <- ndvi

# Now replace raster cell values with kmncluster$cluster array
knr[] <- kmncluster$cluster

# Alternative
values(knr) <- kmncluster$cluster
knr
```

We can see that `knr` is a RasterLayer but we do not know which cluster (1-10) belongs what LULC class. You can find that out by plotting them side-by-side with other reference layer and using unique color for each cluster.

```{r kmeansplot, fig.height=4, fig.width=8}

# Define a color vector for 10 clusters (learn more about setting the color later)
mycolor <- c("#fef65b","#ff0000", "#daa520","#0000ff","#0000ff","#00ff00","#cbbeb5",
             "#c3ff5b", "#ff7373", "#00ff00", "#808080")

par(mfrow = c(1,2))
plot(ndvi, col = rev(terrain.colors(10)), main = 'Landsat-NDVI')
plot(knr, main = 'Unsupervised classification', col = mycolor )
```

While for other purposes it is usually better to define more classes (and possibly fuse classes later), a simple classification like this one could be useful, e.g., merge cluster 4 and 5 to construct a water mask for the year 2011.

**Important** These 10 clusters are not useful unless you re-label them with LULC information class. You can save the raster output of clustering and open it in GIS platform (e.g. [QGIS](https://qgis.org/en/site/about/index.html)) and assign classes to each clusters. Multiple clusters can have the same class! A tutorial can be found [here] (http://wiki.awf.forst.uni-goettingen.de/wiki/index.php/Unsupervised_classification_(Tutorial)). You can skip step 1 in the tutorial which provides guidelines for generating clusters.

You can change the colors in my `mycolor`. Learn more about selecting colors in R [here](http://www.melissaclarkson.com/resources/R_guides/documents/colors_Ver2.pdf) and [here](https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/colorPaletteCheatsheet.pdf).

**Exercise 3** Plot 3-band RGB of `landsat5` for the subset (extent `e`) and result of `kmeans` clustering side-by-side and make a table of land-use land-cover labels for the clusters. E.g. cluster 4 and 5 are water. 

### Supervised classification

In a supervised classification, we have prior knowledge about some of the land-cover types through, for example, fieldwork, reference GIS layers or interpretation of high resolution imagery (such as available on Google maps). Specific sites in the study area that represent homogeneous examples of these known land-cover types are identified. These areas are commonly referred to as training sites because the spectral properties of these sites are used to train the classification algorithm. 

The following examples uses a Classification and Regression Trees (CART) classifier (Breiman et al. 1984) ([further reading](https://doi.org/10.1016/S0034-4257(97)00049-7) to predict land use land cover classes in the study area.

We will perform the following steps before the classification:  

* Read NLCD 2011 reference raster   
* Generate sample sites based on the NLCD 2011 reference raster  
* Extract layervalues from `landsat5` for the sample sites  
* Split the sample sites into training and validation samples  
* Train the classifier using training samples  
* Classify `landsat5` RasterStack using the trained model  
* Test the accuracy of the classified map using validation samples  
   
  
#### Read NLCD 2011 reference raster   

[National Land Cover Database 2011 (NLCD 2011)](https://www.mrlc.gov/nlcd2011.php) is the most recent national land cover product created by the Multi-Resolution Land Characteristics (MRLC) Consortium covering entire USA. NLCD is a 30-m Landsat-based land cover database spanning 4 epochs (1992, 2001, 2006 and 2011). NLCD 2011 is based primarily on a decision-tree classification of circa 2011 Landsat satellite data. 

You can find the classnames in NCLD 2011 (here)[https://www.mrlc.gov/nlcd11_leg.php]. It has two pairs of classvalues and classnames that correspond to the levels of land use and land cover classification system. These levels usually represent the level of complexity, level I being the simplest with broad land use land cover categories. Read [this report by Anderson et al](https://pubs.usgs.gov/pp/0964/report.pdf) to learn more about this land use and land cover classification system for use with Remote Sensor data. 

```{r nlcd}
nlcd <- brick('ABT182-nlcd-L1.tif')
names(nlcd) <- c("nlcd2001","nlcd2011")

# Now we will supply the classnames and colors for plotting
nlcdclass <- c("Water", "Developed", "Barren", "Forest", "Shrubland", "Herbaceous", "Planted/Cultivated", "Wetlands")
classdf <- data.frame(classvalue1 = c(1,2,3,4,5,7,8,9), classnames1 = nlcdclass) 

# Hex codes of colors
classcolor <- c("#5475A8", "#B50000", "#D2CDC0", "#38814E", "#AF963C", "#D1D182", "#FBF65D", "#C8E6F8") 

# Now we ratify (RAT = "Raster Attribute Table") the ncld2011 (define RasterLayer as a categorical variable). This is helpful for plotting. 
nlcd2011 <- nlcd[[2]]
nlcd2011 <- ratify(nlcd2011)
rat <- levels(nlcd2011)[[1]]

# 
rat$landcover <- nlcdclass
levels(nlcd2011) <- rat
```

We did a lot of things here. Take a step back and read more about `ratify`.

**Note** There is no class with value 6.  

#### Generate sample sites based on the NLCD 2011 reference raster
As we discussed in the class, training and/or validation data can come from a variety of sources. In this example we will generate the training and validation sample sites using the NLCD reference RasterLayer. Alternatively, you can use predefined sites that you may have collected from other sources. We will generate the sample sites following a stratified random sampling to ensure samples from each LULC class.

```{r training sites}
# Load the training sites locations
# Set the random number generator to reproduce the results
set.seed(99)

# Sampling
samp2011 <- sampleStratified(nlcd2011, size = 200, na.rm = TRUE, sp = TRUE)
samp2011
# Number of samples in each class
table(samp2011$nlcd2011)
```

You can see there are two variables in `samp2011`. The `cell` column contains cell numbers of `nlcd2011` sampled. `nlcd2011` column contains the class values (1-9). We will drop the `cell` column later. 

Here `nlcd` has integer values between 1-9. You will often find classnames are provided as string labels (e.g. water, crop, vegetation). You will need to 'relabel' class names to integer or factors if only string labels are supplied before using them as response variable in the classification. There are several approaches that could be used to convert these classes to integer codes. We can make a function that will reclassify the character strings representing land cover classes into integers based on the existing factor levels.

Let's plot the training sites over the `nlcd2011` RasterLayer to visualize the distribution of sampling locations.

```{r plots, fig.height=8, fig.width=8}
require(rasterVis)
levelplot(nlcd2011, col.regions = classcolor, main = 'Distribution of Training Sites')+
  layer(sp.points(samp2011, pch = 3, cex = 0.5, col = 1))
```

`rasterVis` offers more advanced (trellis/lattice) plotting of Raster* objects. Please install the package if it is not available for your machine.

#### Extract layervalues from `landsat5` for the sample sites

Once we have the sites, we can extract the band values from `landsat5` RasterStack. These band values will be the predictor variables and classvalues (`nlcd2011`) will be the response variable.

```{r extractvalues}
# Extract the layer values for the locations
sampvals <- extract(landsat5, samp2011, df = TRUE)

# sampvals no longer has the spatial information. To keep the spatial information you use `sp = TRUE` argument in `extract` function. 

# drop the ID column
sampvals <- sampvals[, -1]

# combine the class information with extracted values
sampdata <- data.frame(classvalue = samp2011@data$nlcd2011, sampvals)
```

#### Split the sample sites into training and validation samples

We will now split the sample sites into training and validation. Using the function `dismo::kfold` we can split the dataset into `k` groups. One of the groups will be used for validation while rest of them will be used for training.

```{r}
library(dismo)
set.seed(99)

j <- kfold(sampdata, k = 5, by = sampdata$classvalue)

training2011 <- sampdata[j!= 1, ] # selected the rows where j equals 1
validation2011 <- sampdata[j == 1, ] # selected the rows where j equals [2:k]

# you can check the number of samples in each category 
# uncomment and run the following
#table(samp2011$classnames)
#table(training2011$classnames)
#table(validation2011$classnames)
```

We have performed a 80-20 split for the training and validation samples. Number of validation samples are generally lower than training samples. You can try different partition ratio or use
[cross-validation](http://onlinelibrary.wiley.com/doi/10.1890/11-0826.1/abstract).   


#### Train the classifier using training samples 

Now we will train the classification algorithm using `training2011` dataset. 

```{r, fig.height=6, fig.width=6}
library('rpart') 
#Please install the package if it is not available for your machine.

# Train the model
cart <- rpart(as.factor(classvalue)~., data = training2011, method = 'class', minsplit = 5)

# print(model.class)

# Much cleaner way is to plot the trained classification tree
plot(cart, uniform=TRUE, main="Classification Tree")
text(cart, cex = 0.8)
```

In the classification tree plot classvalues are printed at the leaf node. You can find the corresponding land use land cover names from the `classdf` dataframe. 

See `?rpart.control` to set different parameters for building the model.

You can print/plot more about the `cart` model created in the previous example. E.g. you can use `plotcp(cart)` to learn about the cost-complexity (`cp` argument in `rpart`). 

####  Classify `landsat5` RasterStack using the trained model

Once we have a trained classification model (`cart`), we can use that to classify the `landsat5` RasterStack.

**Important** The names in the Raster object to be classified should exactly match those expected by the model. This will be the case if the same Raster object was used (via extract) to obtain the values to fit the model (previous example). 

```{r prediction}
# Now predict the subset data based on the model; prediction for entire area takes longer time
pr2011 <- predict(landsat5, cart, type='class', progress = 'text')

# Check the type of predicted variable
pr2011
```

Now plot the classification result using `rasetrVis`. See will set the `classnames` for the `classvalues`.

```{r fig.width=8, fig.height=8}
pr2011 <- ratify(pr2011)

rat <- levels(pr2011)[[1]]

rat$legend <- classdf$classnames

levels(pr2011) <- rat

levelplot(pr2011, maxpixels = 1e6,
          col.regions = classcolor,
          scales=list(draw=FALSE),
          main = "Decision Tree classification of Landsat 5")
```

**Exercise 4** Plot `nlcd2011` and `pr2011` side-by-side and comment about the accuracy of the prediction (e.g. mixing between cultivated crops, pasture, grassland and shrubs). 

You may need to select more samples and use additional predictor variables. The choice of classifier also plays an important role.

#### Test the accuracy of the classified map using validation samples

Accuracy assessment of the classified map is required to test the quality of the product. Two widely reported measures in remote sensing community are overall accuracy and kappa statistics value. You can perform the accuracy assessment using the independent samples (`validation2011`).

First we will predict the classes using predictor variable in the `validation2011` and `cart` model

```{r}
# predict (see the position of the arguments is different from raster predictions)
prclass <- predict(cart, validation2011[,2:ncol(validation2011)], type='class')

# create a dataframe using the reference and prediction
conmat <- data.frame(prediction = prclass, reference = validation2011$classvalue)

# create the confusion matrix
conmat <- table(conmat)

# change the name of the classes
colnames(conmat) <- classdf$classnames
rownames(conmat) <- classdf$classnames
print(conmat)
```

**Exercise 5** Comment on the miss-classification between different LULC classes.

**Exercise 6** List few suggestions to improve the accuracy.

**Compute overall accuracy and Kappa statistics**
```{r Accuracy Statistics}

# number of instances
n <- sum(conmat) 

# Total number of validation samples
print(n)

# Total number of classes
nc <- nrow(conmat) 
print(nc)

# number of correctly classified instances per class
diag <- diag(conmat) 

# number of instances per class
rowsums <- apply(conmat, 1, sum) 

# number of predictions per class
colsums <- apply(conmat, 2, sum) 

# distribution of instances over the actual classes
p <- rowsums / n 

# distribution of instances over the predicted classes
q <- colsums / n 

# Overall Accuracy
OA <- sum(diag) / n

# Calculate Kappa statistics
expAccuracy <- sum(p*q)
kappa <- (OA - expAccuracy) / (1 - expAccuracy)

print(OA)
print(kappa)
```

**Compute producer and use accuracy**
```{r User/Producer accuracy}

# Producer accuracy
PA <- diag / colsums

# User accuracy
UA <- diag / rowsums

outAcc <- data.frame(producerAccuracy = PA, userAccuracy = UA)

print(outAcc)
```

**Exercise 7** Please perform the classification using Random Forest classifiers from the package [`randomForest`](https://cran.r-project.org/web/packages/randomForest/index.html). For help see this [discussion](https://gis.stackexchange.com/questions/39021/how-to-perform-random-forest-land-cover-classification).

**Exercise 8** Plot the results of `rpart` and 'rf` classifier side-by-side.  

**Exercise (optional)** Please repeat the steps for the year 2001 using `rpart`. You will use cloud-free composite image from [Landsat 7](https://landsat.gsfc.nasa.gov/landsat-7/) with 6-bands. The reference data will be the [National Land Cover Database 2001 (NLCD 2001)](https://www.mrlc.gov/nlcd2011.php) for the subset of the Central Valley regions.

**Exercise(optional)** You have been training your classifiers using 160 samples for each class. Now we want to see the effect of sample size on classification. Please repeat the steps with different subset of the sample size (e.g. 120, 100). Use the same holdout samples for accuracy assessment.  


## Resources:  
-[Remote Sensing Digital Image Analysis](http://www.springer.com/us/book/9783642300615)  
-[Introductory Digital Image Processing: A Remote Sensing   Perspective](https://www.pearsonhighered.com/program/Jensen-Introductory-Digital-Image-Processing-A-Remote-Sensing-Perspective-4th-Edition/PGM30020.html)   
-[A survey of image classification methods and techniques for improving classification performance](http://www.tandfonline.com/doi/pdf/10.1080/01431160600746456)  
-[A Review of Modern Approaches to Classification of Remote Sensing Data](http://link.springer.com/chapter/10.1007%2F978-94-007-7969-3_9)  
-[Online remote sensing course](http://nptel.ac.in/courses/105108077/)  

## Packages developed for analyzing remote sensing:  
Remote sensing R packages:  
-[RStoolbox](https://cran.r-project.org/web/packages/RStoolbox/index.html)  
-[landsat](https://cran.r-project.org/web/packages/landsat/index.html)  
-[hsdar](https://cran.r-project.org/web/packages/hsdar/index.html)  
-Raster visualization: [rasterVis](https://cran.r-project.org/web/packages/rasterVis/index.html)  
